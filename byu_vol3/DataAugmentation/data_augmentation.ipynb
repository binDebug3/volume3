{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Volume 3: Data Augmentation.</h1>\n",
    "\n",
    "    NAME\n",
    "    Section #\n",
    "    DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Image Augmentation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Problem 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(image, A, B): \n",
    "    \"\"\"Returns the image translated by a random amount (a,b), where\n",
    "    a~Uniform(-A,A) and b~Uniform(-B,B). The resulting image should be cropped\n",
    "    to be of size (d1,d2). Note that this translation will leave a border on\n",
    "    two sides of the image. Fill the empty border with the parts that were cropped\n",
    "    off the opposite sides.\n",
    "        Parameters:\n",
    "            image (d1,d2): d1 x d2 array \n",
    "            A (float): horizontal translation parameter\n",
    "            B (float): vertical translation parameter\n",
    "        Returns:\n",
    "            translated_image (d1,d2): array of translated image\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 1: Translate')\n",
    "    \n",
    "    \n",
    "def rotate(image, theta): \n",
    "    \"\"\" Returns an image rotated by a random amount t~Uniform(-theta,theta).\n",
    "    The resulting image should be cropped to be the same size as the original,\n",
    "    and any blank parts should be filled with one of the parts cropped off the\n",
    "    other side.\n",
    "        Parameters:\n",
    "            image (d1,d2): d1 x d2 array\n",
    "            theta (float): largest acceptable rotation angle\n",
    "        Returns:\n",
    "            rotated_image (d1,d2): array of rotated image\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 1: Rotate')\n",
    "\n",
    "    \n",
    "def skew(image, A): \n",
    "    \"\"\" Returns an image with the linear transformation [[1,a],[0,1]] applied,\n",
    "    where a~Uniform(-A,A). Crop the parts that go outside the image boundaries\n",
    "    and fill missing areas with the appropriate cropped piece.\n",
    "        Parameters:\n",
    "            image (d1,d2): d1 x d2 array\n",
    "            A (float): skew parameter\n",
    "        Returns:\n",
    "            skewed_image (d1,d2): array of skewed image\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 1: Skew')\n",
    "    \n",
    "\n",
    "def flip_horizontal(image):\n",
    "    \"\"\"Flip horizontal. Returns a horizontally flipped version of the image.\n",
    "        Parameters:\n",
    "            image (d1,d2): d1 x d2 image array \n",
    "        Returns:\n",
    "            flipped_image (d1,d2): array of flipped image\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 1: flip_horizontal')\n",
    "\n",
    "    \n",
    "def gauss_noise(image, sigma2): \n",
    "    \"\"\"Adds Gaussian noise with parameter sigma2. For the image draw d1xd2 random\n",
    "    noise values from N(0,sigma2) and add those to the original image.\n",
    "        Parameters:\n",
    "            image (d1,d2): d1 x d2 array \n",
    "        Returns:\n",
    "            noisy_image: array of noisy image\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 1: gauss_noise')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Problem 2 </h3>\n",
    "Take the sklearn digits dataset, make an 80-20 train-test split, then apply \n",
    "each of your transformations to the entire training set. You must decide good \n",
    "values of each of the parameters to use---justify each choice.\n",
    "This should give you a larger (augmented) training set with roughly 8,600 \n",
    "training points. Fit a random forest to the augmented training set and to the \n",
    "original training set and return the results of each on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augment(X,Y,parameters):\n",
    "    \"\"\" transform the images using the functions above. \n",
    "    Parameters:\n",
    "        X (N,d1,d2): array containing N images of dimension d1 x d2\n",
    "        Y (N,): Labels/values for each image\n",
    "        parameters: List of parameter values [A,B,theta,A,sigma2]\n",
    "    Returns:\n",
    "        augmented_X (6N,d1,d2): original and transformed data in one array \n",
    "        augmented_Y (6N): corresponding labels/values\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 2: image_agument')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Audio Augmentation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Problem 3 </h3>\n",
    "The file music.npy contains the audio time series data from 10 second clips of 150 different songs, with styles.npy describing the associated style of ballroom dance. The styles included are Chacha, Foxtrot, Jive, Samba, Rumba, and Waltz. Use train_test_split\n",
    "from sklearn.model_selection with test_size=.5 to create train and test sets. Create two training sets by augmenting this original training set. Each new augmented\n",
    "training set will include the original data and the augmented data. For the first, add ambient\n",
    "noise from the file restaurant-ambience.wav. For the second, use time_stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Problem 4</h3>\n",
    "\n",
    "Do the following steps 5 times:\n",
    "\n",
    "• Use the original data set and the augmented data sets to fit three RandomForestClassifiers,\n",
    "one only on the original data, one on the original data and the data with ambient noise\n",
    "added, and one on the original data and the time stretched data.\n",
    "\n",
    "• Score each classifier.\n",
    "\n",
    "Print the mean score for each of the classifiers and print the standard deviation for the scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">SMOTE</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Problem 5 </h3>\n",
    "\n",
    "Write a function that uses the synthetic minority oversampling technique to augment an imbalanced data set.\n",
    "Your function should have the following characteristics:\n",
    "\n",
    "Accept $X$, a matrix of minority class samples\n",
    "       $N$, the number of samples to generate per original point\n",
    "       $k$, the number of nearest neighbors.\n",
    "\n",
    "For each original point in the sample, pick one of the $k$ nearest neighbors at random and generate a new point that lies between the two original values. \n",
    "\n",
    "Return an array containing the synthetic samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X,N,k):\n",
    "    \"\"\" Generate synthetic points using the SMOTE method. Hint! Use KDTree :)\n",
    "    Parameters:\n",
    "        X (n,m): minority class samples\n",
    "        N (int): number of samples to generate from each point\n",
    "        k (int): number of nearest neighbors\n",
    "    Returns:\n",
    "        synthetic ndarray(N*n,m): synthetic minority class samples\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Problem 5: SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Problem 6 </h3>\n",
    "\n",
    "The dataset found in creditcard.npy contains information about credit card purchases made over a two day period. \n",
    "Of the approximately 285,000 observations, 492 are fraudulent purchases. \n",
    "The last column indicates if the purchase was valid (0) or fraudulent (1). \n",
    "\n",
    "Do the following steps 10 times:\n",
    "\n",
    "• Create a training and test set from the data using train_test_split from sklearn.\n",
    "model_selection with test_size=.7.\n",
    "\n",
    "• Use smote with N = 500 and k = 2 to augment the training set.\n",
    "\n",
    "• Create two Gaussian Naïve Bayes classifiers (from sklearn.naive_bayes.GaussianNB),\n",
    "one which wil be trained on only the original data and the other on the SMOTE augmented\n",
    "data and the original data.\n",
    "\n",
    "• Fit each classifier and find the recall and accuracy of each model.\n",
    "\n",
    "Print the mean recall and mean accuracy of each model and and describe the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
