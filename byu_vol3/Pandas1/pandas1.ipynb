{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hr6QvWC1sVno"
   },
   "source": [
    "# Pandas 1\n",
    "\n",
    "## Name Dallin Stewart\n",
    "\n",
    "## Class ACME 002\n",
    "\n",
    "## Date A long time ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1pxi6sWEcmJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8nzrZCaE4bn"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1\n",
    "def prob1(file='budget.csv'):\n",
    "    \"\"\"\"\n",
    "    Read in budget.csv as a DataFrame with the index as column 0 and perform each of these operations on the DataFrame in order. \n",
    "    \n",
    "    1) Reindex the columns such that amount spent on groceries is the first column and all other columns maintain the same ordering.\n",
    "    2) Sort the DataFrame in descending order based on how much money was spent on Groceries.\n",
    "    3) Reset all values in the 'Rent' column to 800.0.\n",
    "    4) Reset all values in the first 5 data points to 0.0\n",
    "    \n",
    "    Return the values of the updated DataFrame as a NumPy array.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): name of datafile\n",
    "        \n",
    "    Return:\n",
    "        values (ndarray): values of DataFrame\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "\n",
    "    # 1) Reindex the columns such that 'Groceries' comes first\n",
    "    cols = ['Groceries'] + [col for col in df.columns if col != 'Groceries']\n",
    "    df = df[cols]\n",
    "\n",
    "    # 2) Sort the DataFrame in descending order based on 'Groceries' column\n",
    "    df.sort_values(by='Groceries', ascending=False, inplace=True)\n",
    "\n",
    "    # 3) Reset all values in the 'Rent' column to 800.0\n",
    "    df['Rent'] = 800.0\n",
    "\n",
    "    # 4) Reset all values in the first 5 data points to 0.0\n",
    "    df.iloc[:5] = 0.0\n",
    "\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcGE9Qq5scpv"
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZIdjL74RuuO"
   },
   "outputs": [],
   "source": [
    "# Prob 2\n",
    "def prob2(file='budget.csv'):\n",
    "    \"\"\"\n",
    "    Read in file as DataFrame.\n",
    "    Fill all NaN values with 0.0.\n",
    "    Create two new columns, 'Living Expenses' and 'Other'. \n",
    "    Sum the columns 'Rent', 'Groceries', 'Gas' and 'Utilities' and set it as the value of 'Living Expenses'.\n",
    "    Sum the columns 'Dining Out', 'Out With Friends' and 'Netflix' and set as the value of 'Other'.\n",
    "    Identify which column, other than 'Living Expenses' correlates most with 'Living Expenses'\n",
    "    and which column other than 'Other' correlates most with 'Other'.\n",
    "\n",
    "    Return the names of each of those columns as a tuple.\n",
    "    The first should be of the column corresponding to \\li{'Living Expenses'} and the second to \\li{'Other'}.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): name of datafile\n",
    "        \n",
    "    Return:\n",
    "        values (tuple): (name of column that most relates to Living Expenses, name of column that most relates to Other)\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame and fill NaN values with 0.0\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.fillna(0.0)\n",
    "\n",
    "    # Create the 'Living Expenses' column by summing specified columns\n",
    "    df['Living Expenses'] = df[['Rent', 'Groceries', 'Gas', 'Utilities']].sum(axis=1)\n",
    "\n",
    "    # Create the 'Other' column by summing specified columns\n",
    "    df['Other'] = df[['Dining Out', 'Out With Friends', 'Netflix']].sum(axis=1)\n",
    "    \n",
    "    correlations = df.corr()\n",
    "\n",
    "    # Calculate correlations of all columns with 'Living Expenses' and 'Other' columns\n",
    "    correlations_expenses = correlations['Living Expenses'].drop(['Living Expenses', 'Other'])\n",
    "    correlations_other = correlations['Other'].drop(['Living Expenses', 'Other'])\n",
    "\n",
    "    # Find the column with the highest correlation with 'Living Expenses' and 'Other'\n",
    "    most_expenses = correlations_expenses.idxmax()\n",
    "    most_other = correlations_other.idxmax()\n",
    "\n",
    "    return (most_expenses, most_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVHAwFRRseXh"
   },
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35VAshdqZhVD"
   },
   "outputs": [],
   "source": [
    "def prob3(file='crime_data.csv'):\n",
    "    \"\"\"\n",
    "    Read in crime data and use pandas to answer the following questions.\n",
    "    \n",
    "    Set the index as the column 'Year', and return the answers to each question as a tuple.\n",
    "    \n",
    "    1) Identify the three crimes that have a mean over 1,500,000. \n",
    "    Of these three crimes, which two are very correlated? \n",
    "    Which of these two crimes has a greater maximum value?\n",
    "    Save the title of this column as a variable to return as the answer.\n",
    "    \n",
    "    2) Examine the data since 2000.\n",
    "    Sort this data (in ascending order) according to number of murders.\n",
    "    Find the years where Aggravated Assault is greater than 850,000.\n",
    "    Save the indices (the years) of the masked and reordered DataFrame as a NumPy array to return as the answer.\n",
    "    \n",
    "    3) What year had the highest crime rate? \n",
    "    In this year, which crime was committed the most? \n",
    "    What percentage of the total crime that year was it? \n",
    "    Save this value as a float.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        file (str): data\n",
    "    \n",
    "    Return:\n",
    "        ans_1 (string): answer to Question 1\n",
    "        ans_2 (ndarray): answer to Question 2\n",
    "        ans_3 (float): answer to Question 3\n",
    "    \"\"\"\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file, index_col='Year')\n",
    "\n",
    "    # PART 1\n",
    "    # identify the three crimes\n",
    "    mean_over = df.mean() > 1_500_000\n",
    "    crimes_over = mean_over[mean_over][2:].index.tolist()\n",
    "    print(crimes_over)\n",
    "\n",
    "    # calculate correlations between crimes\n",
    "    correlations = df[crimes_over].corr()\n",
    "\n",
    "    # find the two most correlated crimes\n",
    "    most_corr = np.unravel_index(np.argmax(correlations.values - np.eye(correlations.shape[0])), correlations.shape)\n",
    "    corr_crime_1, corr_crime_2 = crimes_over[most_corr[0]], crimes_over[most_corr[1]]\n",
    "\n",
    "    # determine which of the two correlated crimes has a greater maximum value\n",
    "    max_crime1 = df[corr_crime_1].max()\n",
    "    max_crime2 = df[corr_crime_2].max()\n",
    "    most_maxed = corr_crime_1 if max_crime1 > max_crime2 else corr_crime_2\n",
    "\n",
    "\n",
    "    # PART 2\n",
    "    # Sort by number of murders in ascending order\n",
    "    df_since_2000 = df[df.index >= 2000]\n",
    "    df_sorted = df_since_2000.sort_values(by='Murder')\n",
    "\n",
    "    # Find years where Aggravated Assault is greater than 850,000\n",
    "    years = df_sorted[df_sorted['Aggravated Assault'] > 850_000].index.values\n",
    "\n",
    "    \n",
    "    # PART 3\n",
    "    # find the year with highest count of crimes\n",
    "    df['Crime Rate'] = df['Total'] / df['Population']\n",
    "    biggest_year = df['Crime Rate'].idxmax()\n",
    "    \n",
    "    # sort this year ignoring Population and Total then get the index\n",
    "    worst = df.loc[biggest_year].sort_values(ascending=False)[2:].idxmax()\n",
    "    \n",
    "    # compute percentage and save as a float\n",
    "    percent_crime = float(df.loc[biggest_year][worst] / df.loc[biggest_year]['Total'])\n",
    "\n",
    "    return most_maxed, years, percent_crime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Property', 'Burglary', 'Larceny']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Property',\n",
       " array([2000, 2001, 2002, 2003, 2005, 2007, 2006], dtype=int64),\n",
       " 0.8997188308734142)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pfN6PbxsgC3"
   },
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAavKLA17LsN"
   },
   "outputs": [],
   "source": [
    "def prob4(file='DJIA.csv'):\n",
    "    \"\"\"\n",
    "\n",
    "    Read the data with a DatetimeIndex as the index.\n",
    "    Drop rows any rows without numerical values, cast the \"VALUE\" column to floats, then return the updated DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        df (DataFrame): updated DataFrame of stock market data\n",
    "    \"\"\"\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file, dtype={'VALUE':np.float64}, na_values='.')\n",
    "\n",
    "    # remove rows with non-numeric values in \"VALUE\" \n",
    "    df.set_index(pd.to_datetime(df['DATE']), inplace=True)\n",
    "    df.drop(columns='DATE', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I663KesNsjMK"
   },
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob5(file='paychecks.csv'):\n",
    "    \"\"\"\n",
    "    Create data_range for index of paycheck data.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        df (DataFrame): DataFrame of paycheck data\n",
    "    \"\"\"\n",
    "    # read in the fil\n",
    "    df = pd.read_csv(file, names=['Pay Amount'])\n",
    "    \n",
    "    # create datetime index for March 13th, 2008\n",
    "    ind_df = pd.date_range(start='3/13/2008', periods=93, freq='2W-FRI')\n",
    "    \n",
    "    # set the index column to be datetime index\n",
    "    df.set_index(ind_df, inplace=True)\n",
    "    df.index.rename('Date', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I663KesNsjMK"
   },
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGxh0mpSDLDD"
   },
   "outputs": [],
   "source": [
    "def prob6(file='DJIA.csv'):\n",
    "    \"\"\"\n",
    "    Compute the following information about the DJIA dataset\n",
    "    1. The single day with the largest gain\n",
    "    2. The single day with the largest loss\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        max_day (<M8[ns]): DateTimeIndex of maximum change\n",
    "        min_day (<M8[ns]): DateTimeIndex of minimum change\n",
    "    \"\"\"\n",
    "    # use prob4 to load cleaned file data\n",
    "    df = prob4(file)\n",
    "    \n",
    "    # obtain shifted dates\n",
    "    shifts = df - df.shift(1)\n",
    "    \n",
    "    # get days for maxes and mins\n",
    "    ind_max = shifts.idxmax()\n",
    "    ind_min = shifts.idxmin()\n",
    "\n",
    "    return ind_max[0], ind_min[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
